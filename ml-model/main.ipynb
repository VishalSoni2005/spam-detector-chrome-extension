{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36bd28f6-b97f-4419-9899-f414cd738f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/home/soni/Desktop/spam-detector-extension/ml-model/sms+spam+collection/SMSSpamCollection\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"label\", \"text\"],\n",
    ")\n",
    "df[\"label_num\"] = df[\"label\"].map({\"spam\": 1, \"ham\": 0})\n",
    "\n",
    "# df2 = pd.read_csv(\"../Machine Learning/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867664ce-783b-41b9-a47d-791bfa8f9719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5572, 3)\n",
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n",
      "Entries (spam + ham):  5572\n"
     ]
    }
   ],
   "source": [
    "# quick EDA\n",
    "\n",
    "# df['label'].count()\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df[\"label\"].value_counts())\n",
    "print(\"Entries (spam + ham): \", df[\"label\"].count())\n",
    "# print(df.sample(5).to_dict(orient='records'))\n",
    "# print(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac373579-bbfd-4a26-96bb-a3e013f363ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MultinomialNB ===\n",
      "Accuracy: 97.04035874439462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98       966\n",
      "        spam       1.00      0.78      0.88       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.89      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Confusion matrix:\n",
      " [[966   0]\n",
      " [ 33 116]]\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"label_num\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# converting raw text data into vector (number)\n",
    "\n",
    "# Raw SMS → vectorizer (numbers) → model → prediction\n",
    "tfidf_params = {  # These are extra settings for the TfidfVectorizer\n",
    "    \"tfidf__ngram_range\": (1, 2 ), # use single words (unigrams) + pairs of words (bigrams)\n",
    "    \"tfidf__min_df\": 2,  # ignore very rare words (appear in only 1 doc)\n",
    "    \"tfidf__max_df\": 0.9,  # ignore super common words (appear in >90% docs)\n",
    "    \"tfidf__stop_words\": \"english\",  # remove common English stop words (like \"the\", \"is\")\n",
    "}\n",
    "\n",
    "pipe_nb = Pipeline([\n",
    "   (\"tfidf\", TfidfVectorizer()),\n",
    "   (\"clf\", MultinomialNB())\n",
    "])\n",
    "# pipe_nb → TF-IDF → Naive Bayes\n",
    "\n",
    "# # 3 MNB\n",
    "pipe_nb.set_params(**tfidf_params)\n",
    "pipe_nb.fit(X_train, y_train)\n",
    "y_pred_nb = pipe_nb.predict(X_test)\n",
    "print(\"=== MultinomialNB ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb) * 100)\n",
    "print(classification_report(y_test, y_pred_nb, target_names=[\"ham\", \"spam\"]))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c158e2f-9cdc-4c0c-9359-82c6ce4a7ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LogisticRegression ===\n",
      "Accuracy: 0.9704035874439462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98       966\n",
      "        spam       1.00      0.78      0.88       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.89      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Confusion matrix:\n",
      " [[966   0]\n",
      " [ 33 116]]\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = Pipeline(\n",
    "    [(\"tfidf\", TfidfVectorizer()), (\"clf\", LogisticRegression(max_iter=1000))]\n",
    ")\n",
    "\n",
    "# pipe_lr → TF-IDF → Logistic Regression\n",
    "\n",
    "# 4. Fit Logistic Regression (stronger baseline)\n",
    "pipe_lr.set_params(**tfidf_params)\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred_lr = pipe_lr.predict(X_test)\n",
    "print(\"=== LogisticRegression ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr, target_names=[\"ham\", \"spam\"]))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7f75cd9-3a49-41ad-ba3a-60a518c69661",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T07:12:58.595750Z",
     "iopub.status.busy": "2025-09-18T07:12:58.595361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LogisticRegression (threshold=0.4) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       966\n",
      "        spam       0.99      0.85      0.91       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "NB CV F1 scores: [0.88888889 0.86363636 0.85384615 0.86692015 0.86692015] mean: 0.8680423421107832\n",
      "GridSearch best params: {'clf__alpha': 0.1, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2)}\n",
      "Best CV f1: 0.942746468204223\n"
     ]
    }
   ],
   "source": [
    "# 5. Example: adjust threshold for LR (if you want more recall on spam)\n",
    "probs = pipe_lr.predict_proba(X_test)[:, 1]  # probability of 'spam'\n",
    "threshold = 0.4\n",
    "y_pred_thresh = (probs >= threshold).astype(int)\n",
    "\n",
    "print(f\"=== LogisticRegression (threshold={threshold}) ===\")\n",
    "print(classification_report(y_test, y_pred_thresh, target_names=[\"ham\", \"spam\"]))\n",
    "\n",
    "# 6. Quick cross-validation (F1) for NB\n",
    "cv_scores = cross_val_score(pipe_nb, X, y, cv=5, scoring=\"f1\", n_jobs=-1)\n",
    "print(\"NB CV F1 scores:\", cv_scores, \"mean:\", cv_scores.mean())\n",
    "\n",
    "# 7. Small hyperparameter grid search example (for NB)\n",
    "param_grid = {\n",
    "    \"tfidf__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"tfidf__min_df\": [1, 2],\n",
    "    \"clf__alpha\": [0.1, 0.5, 1.0],  # Laplace smoothing\n",
    "}\n",
    "gs = GridSearchCV(pipe_nb, param_grid, cv=4, scoring=\"f1\", n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"GridSearch best params:\", gs.best_params_)\n",
    "print(\"Best CV f1:\", gs.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e4b21e1-b64b-4f0a-973c-55372ce8f922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to sms_spam_classifier.pkl\n",
      "Predictions: [1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8. Save your best model (choose whichever performed better; here LR example)\n",
    "joblib.dump(pipe_lr, \"./sms_spam_classifier.pkl\")\n",
    "\n",
    "print(\"Saved model to sms_spam_classifier.pkl\")\n",
    "\n",
    "# # 9. Example predict\n",
    "loaded = joblib.load(\"./sms_spam_classifier.pkl\")\n",
    "samples = [\n",
    "    \"Congratulations! You've won a $1000 Walmart gift card. Reply WIN to claim.\",\n",
    "    \"Hey, are we meeting for dinner tonight?\",\n",
    "]\n",
    "print(\"Predictions:\", loaded.predict(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd8caa-df33-4c20-a939-d01780e39b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc2616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f1ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711180f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
